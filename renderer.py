import jax
from absl import app, flags

import jax.numpy as jnp
import optax
import flax
from flax.training import checkpoints, train_state
from flax.metrics import tensorboard
import tensorflow as tf
import numpy as np
import functools
import yaml
import cv2
import os
from dataclasses import dataclass

from nerf import (
    get_model,
    get_nerf,
)
from nerf_config import get_config, NerfConfig
from datasets import dataset_factory, trans, rot_z, rot_y, rot_x


def get_nerf_eval_func(config: NerfConfig):
    """Return NeRF function for evaluation"""
    return get_nerf(
        near=config.near,
        far=config.far,
        L_position=config.L_position,
        L_direction=config.L_direction,
        num_samples_coarse=config.num_samples_coarse,
        num_samples_fine=config.num_samples_fine,
        use_hvs=config.use_hvs,
        use_direction=True,
        use_random_noise=False,
    )


def render_step(nerf_func, state, val_data, eval_batch_size):
    """
    Render step, takes in an entire image and returns the predicted image

    Inputs:
        nerf_func: a function performs the nerf algorithm
        state: replicated train state
        val_data: origins and directions of rays each with [H, W, 3]
        eval_batch_size: batch size for evaluation
    Outputs:
        pred_img: predicted images [H, W, 3]
        depth_img: predicted images [H, W, 3]

    """

    # for eval key stays the same
    key = jax.random.PRNGKey(0)

    eval_origins = val_data[0]
    eval_directions = val_data[1]

    origins_flattened = eval_origins.reshape(-1, 3)
    directions_flattened = eval_directions.reshape(-1, 3)

    pred_img_parts = []
    pred_depth_parts = []
    for i in range(0, origins_flattened.shape[0], eval_batch_size):
        origin = origins_flattened[i : i + eval_batch_size]
        direction = directions_flattened[i : i + eval_batch_size]

        (rendered, rendered_hvs), weights, ts = nerf_func(
            params=state.params,
            key=key,
            origins=origin,
            directions=direction,
        )

        depth_hvs = jnp.sum(weights * ts, -1)

        pred_img_parts.append(rendered_hvs)
        pred_depth_parts.append(depth_hvs)

    # Reshape image
    pred_img = jnp.concatenate(pred_img_parts, axis=0)
    pred_img = pred_img.reshape(eval_origins.shape)

    # expand dims tf.ssims expects [B, H, W, C]
    pred_img = jnp.expand_dims(pred_img, axis=0)

    # Reshape depth image
    pred_depth = jnp.concatenate(pred_depth_parts, axis=0)
    pred_depth = pred_depth.reshape(eval_origins.shape[:-1])
    pred_depth = jnp.expand_dims(pred_depth, axis=[0, -1])

    return pred_img, pred_depth


def save_img(img, file_path, multiplier=255.0):
    img = np.asarray(img * multiplier).astype(np.uint8)
    img = np.squeeze(img)

    cv2.imwrite(file_path, img)

    return img


def render_nerf(config: NerfConfig, render_output_folder: str, display_render: bool):
    """
    Render NeRF model based the poses generated by `custom_path_generator`
    function below.
    """
    dataset = dataset_factory(config)

    # Set near and far for LLFF datasets
    if config.dataset_type == "llff":
        # set near and far to calculated values
        config.near = dataset["train"].near
        config.far = dataset["train"].far

    # Load model and state
    model, _ = get_model(config.L_position, config.L_direction)
    state_dict = checkpoints.restore_checkpoint(config.load_ckpt_dir, target=None)
    eval_state = train_state.TrainState.create(
        apply_fn=model, params=state_dict["params"], tx=optax.adam(1)
    )

    # Create nerf function
    eval_nerf_func = get_nerf_eval_func(config)
    jit_eval_nerf_func = jax.jit(functools.partial(eval_nerf_func, model_func=model))

    def custom_path_generator(poses):
        """
        Generate rendering poses from training set poses.

        Args:
            poses (numpy.ndarray): An array of camera poses.

        Returns:
            A list of rendering poses.

        """
        c2w = poses.mean(0)

        if c2w.shape[0] == 3:
            c2w = np.vstack([c2w, np.array([0, 0, 0, 1])])

        position = np.array([0.0, 0.0, 0.6])
        angle = np.array([0.0, 0.0, 0.0])

        dPosition = np.array([-0.03, 0.0, -0.07])
        dAngle = np.array([0.0, 0.01, 0.0])

        render_poses = []  # <- render poses

        max_render_length = 140
        dt = 0.5
        for idx in range(1, max_render_length):
            rot_mat = rot_x(angle[0]) @ rot_y(angle[1]) @ rot_z(angle[2])
            trans_mat = trans(*position)
            transformed_c2w = trans_mat @ rot_mat @ c2w

            render_poses.append(transformed_c2w)

            # Change delta at specified render steps
            if idx == 40:
                dPosition = np.array([-0.1, 0.01, -0.07])
                dAngle = np.array([0, 0.1, 0.0])

            if idx == 60:
                dPosition = np.array([0.07, -0.02, 0.13])
                dAngle = np.array([0.02, -0.09, -0.01])

            if idx == 90:
                dPosition = np.array([0.1, 0.0, 0.05])
                dAngle = np.array([-0.02, 0.02, -0.11])

            position += dt * dPosition
            angle += dt * dAngle

        return render_poses

    # Set rendering poses for dataset
    dataset["render"].render_poses = custom_path_generator(dataset["render"].poses)

    # Render images and save to file
    for idx, data in enumerate(dataset["render"]):
        print(f"Rendering image {idx}...")
        pred_img, pred_depth = render_step(
            jit_eval_nerf_func, eval_state, data, config.batch_size
        )

        output_folder = f"rendered_imgs_{config.dataset_name}"

        if render_output_folder:
            output_folder = os.path.join(render_output_folder, output_folder)

        output_path = f"{output_folder}/{str(idx).zfill(5)}.png"
        os.makedirs(output_folder, exist_ok=True)
        uint8_img = save_img(pred_img, output_path)
        if display_render:
            cv2.imshow(f"{idx}", uint8_img)
            cv2.waitKey(0)


def nerf_to_mesh(config: NerfConfig):
    """
    This function converts a NeRF model into a 3D mesh
    using Open3D.

    """
    raise NotImplementedError
